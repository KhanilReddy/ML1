{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanilReddy/ML1/blob/main/Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading the entire project folder \"Qualcomm-DL-Hackathon\" from GitHub to your computer/colab\n",
        "!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMHiPrl7fLOB",
        "outputId": "e434873b-3a48-4f3d-8ee7-846c510bbade"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Qualcomm-DL-Hackathon'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 30.68 MiB | 14.52 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def extract_all_files(zip_dir, output_dir):\n",
        "    \"\"\"\n",
        "        This function is to extract all files from ZIP archives located in a specified directory and place them into an output directory.\n",
        "\n",
        "        Args:\n",
        "            zip_dir (:class:`str`): : Required: Directory path in which all zip files are present\n",
        "            output_dir (:class:`str`): Required: Directory path in which all images has to be stored\n",
        "\n",
        "        Example : Extracted all the images from images part-1.zip and images part-2.zip to all_images folder.\n",
        "    \"\"\"\n",
        "    if os.path.exists(zip_dir):\n",
        "      # Get the zip files in zip_dir directory\n",
        "      files = os.listdir(zip_dir)\n",
        "      zip_files = [f for f in files if f.endswith('.zip')]\n",
        "\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "      # Extract each zip file\n",
        "      for zip_file in zip_files:\n",
        "          with zipfile.ZipFile(os.path.join(zip_dir, zip_file), 'r') as zip_ref:\n",
        "              for member in zip_ref.namelist():\n",
        "                  # Extract each file to the output_dir directory without creating subfolders\n",
        "                  filename = os.path.basename(member)\n",
        "                  if filename:\n",
        "                      source = zip_ref.open(member)\n",
        "                      target = open(os.path.join(output_dir, filename), \"wb\")\n",
        "                      with source, target:\n",
        "                          shutil.copyfileobj(source, target)\n",
        "    else:\n",
        "      print(\"f{zip_dir} doesn't exits\")"
      ],
      "metadata": {
        "id": "BI3TJ1GHfaoY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the zip files and the all_images directory\n",
        "train_directory = '/content/Qualcomm-DL-Hackathon/train/'\n",
        "all_images_directory = os.path.join(train_directory , 'all_images')\n",
        "\n",
        "# Extract all files from the zip files in path /content/Qualcomm-DL-Hackathon/train/ to the /content/Qualcomm-DL-Hackathon/train/all_images directory\n",
        "extract_all_files(train_directory, all_images_directory)\n",
        "\n",
        "print(f\"All files have been extracted to {all_images_directory}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRV5Uk4jfiuX",
        "outputId": "be39e0ee-cd24-4bcf-8f0f-cfdf15721919"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files have been extracted to /content/Qualcomm-DL-Hackathon/train/all_images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pandas to read the csv and write the predicted data to csv\n",
        "import pandas as pd\n",
        "\n",
        "# Importing necessary modules from TensorFlow and Keras\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "# Importing necessary modules from scikit-learn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing tqdm for progress bar and numpy for numerical operations\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "DT2FbB2Qfzbm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the training data from a CSV file\n",
        "train = pd.read_csv('/content/Qualcomm-DL-Hackathon/train/train.csv')\n",
        "\n",
        "# Initializing an empty list to store the training images\n",
        "train_img=[]\n",
        "\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "  # Loading the image and resizing it to 224x224 pixels, Converting the image to an array and Appending the image array to the list\n",
        "  temp_img = image.load_img('/content/Qualcomm-DL-Hackathon/train/all_images/'+train['image_names'][i], target_size=(224,224))\n",
        "  temp_img=image.img_to_array(temp_img)\n",
        "\n",
        "  train_img.append(temp_img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ3Ge5h7FBYA",
        "outputId": "5b2fc1a4-c63e-46d3-ef43-536f90cc20c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1646/1646 [00:02<00:00, 643.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def vgg16_model(img_rows, img_cols, channel=1, num_classes=None):\n",
        "    \"\"\"\n",
        "    Builds a VGG16-based convolutional neural network model with custom top layers.\n",
        "\n",
        "    Parameters:\n",
        "    img_rows (int): The number of rows in the input images.\n",
        "    img_cols (int): The number of columns in the input images.\n",
        "    channel (int): The number of channels in the input images (default is 1).\n",
        "    num_classes (int): The number of output classes for the classification task.\n",
        "\n",
        "    Returns:\n",
        "    keras.models.Model: A compiled Keras model ready for training.\n",
        "\n",
        "\n",
        "    Example usage:\n",
        "    model = vgg16_model(img_rows=224, img_cols=224, channel=3, num_classes=10)\n",
        "    \"\"\"\n",
        "    #Loads the VGG16 model with weights pre-trained on the ImageNet dataset and it includes the original fully connected layers at the top of the VGG16 architecture\n",
        "    model = VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "    #remove the last layer of the pre-trained VGG16 model and  clears connections of the last layer..\n",
        "    model.layers.pop()\n",
        "    model.layers[-1].outbound_nodes = []\n",
        "\n",
        "    #Customer layer addition which acts as output layer\n",
        "    x=Dense(num_classes, activation='sigmoid')(model.output)\n",
        "    model=Model(model.input,x)\n",
        "\n",
        "    #To set the first 8 layers to non-trainable (weights will not be updated)\n",
        "    for layer in model.layers[:8]:\n",
        "        layer.trainable = False\n",
        "\n",
        "        # Compile the model with SGD optimizer and binary cross-entropy loss\n",
        "        sgd = SGD(learning_rate=1e-3, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
        "        model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "N1UUhXNYFR5-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the target variable from the training data\n",
        "train_label = train['emergency_or_not'].values\n",
        "\n",
        "# Initializing the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Encoding the target variable\n",
        "train_label = le.fit_transform(train_label)\n",
        "\n",
        "# Converting the encoded labels to categorical format\n",
        "train_label=to_categorical(train_label)\n",
        "train_label=np.array(train_label)\n",
        "\n",
        "# Splitting the data into training and validation sets\n",
        "train_image, valid_image, train_label, valid_label=train_test_split(train_img,train_label,test_size=0.2, random_state=42)\n",
        "\n",
        "# Setting parameters for the model\n",
        "img_rows, img_cols = 224, 224           # Resolution of inputs\n",
        "channel = 3                             # Number of channels (3 for RGB images)\n",
        "num_classes = 2                         # Number of output classes : emergency and Non_emergency\n",
        "batch_size = 32                         # Batch size for training\n",
        "nb_epoch = 15                           # Number of epochs for training\n",
        "\n",
        "# Converting lists to numpy arrays so that they can be efficiently processed by the deep learning model during training and validation.\n",
        "train_image = np.stack(train_image)\n",
        "valid_image = np.stack(valid_image)\n",
        "train_label = np.stack(train_label)\n",
        "valid_label = np.stack(valid_label)\n",
        "\n",
        "# Load our final model\n",
        "model = vgg16_model(img_rows, img_cols, channel, num_classes)"
      ],
      "metadata": {
        "id": "XaHiu9zKFWXQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with necessary input parameters such as input images, labels, batch_size, epochs,\n",
        "model.fit(train_image, train_label,batch_size=batch_size,epochs=nb_epoch,shuffle=True,verbose=1,validation_data=(valid_image, valid_label))\n",
        "\n",
        "combined_data = np.concatenate((train_image, valid_image))\n",
        "combined_labels = np.concatenate((train_label, valid_label))\n",
        "\n",
        "# Train on the combined dataset for 5 more epochs on total data set\n",
        "additional_epochs = 5\n",
        "history_combined = model.fit(combined_data, combined_labels, epochs=additional_epochs, batch_size=batch_size, shuffle=True, verbose=1)\n",
        "\n",
        "predictions_valid = model.predict(valid_image, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Get the class with the highest probability for each prediction\n",
        "validation_prediction = np.argmax(predictions_valid, axis=1)\n",
        "validation_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKZXw6B8Fb9d",
        "outputId": "c84906d2-6ca2-4dd6-cc8b-5701fa29cefe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 623ms/step - accuracy: 0.6469 - loss: 0.6888 - val_accuracy: 0.7909 - val_loss: 0.6715\n",
            "Epoch 2/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 515ms/step - accuracy: 0.8281 - loss: 0.6667 - val_accuracy: 0.8818 - val_loss: 0.6529\n",
            "Epoch 3/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 522ms/step - accuracy: 0.9174 - loss: 0.6464 - val_accuracy: 0.8515 - val_loss: 0.6407\n",
            "Epoch 4/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 555ms/step - accuracy: 0.9231 - loss: 0.6273 - val_accuracy: 0.9030 - val_loss: 0.6178\n",
            "Epoch 5/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 521ms/step - accuracy: 0.9483 - loss: 0.6042 - val_accuracy: 0.9212 - val_loss: 0.5995\n",
            "Epoch 6/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 556ms/step - accuracy: 0.9546 - loss: 0.5884 - val_accuracy: 0.9333 - val_loss: 0.5809\n",
            "Epoch 7/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 516ms/step - accuracy: 0.9699 - loss: 0.5676 - val_accuracy: 0.9091 - val_loss: 0.5705\n",
            "Epoch 8/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 527ms/step - accuracy: 0.9755 - loss: 0.5498 - val_accuracy: 0.9121 - val_loss: 0.5552\n",
            "Epoch 9/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 518ms/step - accuracy: 0.9775 - loss: 0.5325 - val_accuracy: 0.9455 - val_loss: 0.5314\n",
            "Epoch 10/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 522ms/step - accuracy: 0.9813 - loss: 0.5161 - val_accuracy: 0.8970 - val_loss: 0.5402\n",
            "Epoch 11/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 521ms/step - accuracy: 0.9714 - loss: 0.5069 - val_accuracy: 0.9303 - val_loss: 0.5105\n",
            "Epoch 12/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 550ms/step - accuracy: 0.9732 - loss: 0.4921 - val_accuracy: 0.9273 - val_loss: 0.5005\n",
            "Epoch 13/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 520ms/step - accuracy: 0.9842 - loss: 0.4729 - val_accuracy: 0.9364 - val_loss: 0.4901\n",
            "Epoch 14/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 548ms/step - accuracy: 0.9833 - loss: 0.4596 - val_accuracy: 0.9061 - val_loss: 0.4898\n",
            "Epoch 15/15\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 523ms/step - accuracy: 0.9828 - loss: 0.4495 - val_accuracy: 0.8970 - val_loss: 0.4879\n",
            "Epoch 1/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 529ms/step - accuracy: 0.9715 - loss: 0.4420\n",
            "Epoch 2/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 496ms/step - accuracy: 0.9834 - loss: 0.4210\n",
            "Epoch 3/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 487ms/step - accuracy: 0.9807 - loss: 0.4099\n",
            "Epoch 4/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 498ms/step - accuracy: 0.9843 - loss: 0.3988\n",
            "Epoch 5/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 488ms/step - accuracy: 0.9883 - loss: 0.3832\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data from a CSV file\n",
        "test = pd.read_csv('/content/Qualcomm-DL-Hackathon/test.csv')\n",
        "\n",
        "# Initialize an empty list to store the test images\n",
        "test_image = []\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "    # Loading the image and resizing it to 224x224 pixels, Converting the image to an array and Appending the image array to the list\n",
        "    img = image.load_img('/content/Qualcomm-DL-Hackathon/train/all_images/'+test['image_names'][i], target_size=(224,224))\n",
        "    img = image.img_to_array(img)\n",
        "    test_image.append(img)\n",
        "\n",
        "# Convert the list of test images to a numpy array\n",
        "test_image = np.stack(test_image)\n",
        "test_image.shape\n",
        "\n",
        "# Make predictions on the test images\n",
        "predictions_test = model.predict(test_image, batch_size=batch_size, verbose=1)\n",
        "predictions_test\n",
        "\n",
        "# Get the class with the highest probability for each prediction\n",
        "test_prediction = np.argmax(predictions_test, axis=1)\n",
        "test_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2QjAXlEFgJM",
        "outputId": "6b704b9b-14b7-4a7d-eddc-3c2aa8489b8f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 706/706 [00:00<00:00, 991.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the predictions to the test data\n",
        "test['emergency_or_not'] = test_prediction\n",
        "\n",
        "# Save the updated test data with predictions to a new CSV file\n",
        "test.to_csv('/content/Qualcomm-DL-Hackathon/submission_final.csv', header=True, index=False)"
      ],
      "metadata": {
        "id": "1nT4NXlUFtOd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDkChKfW6wYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}