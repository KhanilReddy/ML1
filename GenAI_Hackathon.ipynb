{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#installing and updating the necessary packages to work with Google's generative AI,\n",
        "#the Groq platform, and the integration between LangChain and Groq within your Jupyter Notebook environment\n",
        "\n",
        "%pip install -U -q 'google-genai'\n",
        "%pip install -U -q 'groq'\n",
        "%pip install -U -q 'langchain-groq'"
      ],
      "metadata": {
        "id": "8m9DMqBeWqXy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a CSV file, reads its data, transforms it into JSON format, and saves the JSON data to a new file.\n",
        "# It uses the pandas library for data handling and the json library for JSON conversion\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/testing_data_set.csv')\n",
        "\n",
        "# Convert each row to a JSON object\n",
        "json_list = df.to_dict(orient='records')\n",
        "\n",
        "# Convert the list of JSON objects to a JSON string\n",
        "json_output = json.dumps(json_list, indent=4)\n",
        "\n",
        "# Save the JSON string to a file\n",
        "with open('testing_data_set.json', 'w') as json_file:\n",
        "    json_file.write(json_output)\n",
        "\n",
        "print(\"The CSV file has been successfully converted to JSON format and saved to testing_data_set.json.\")"
      ],
      "metadata": {
        "id": "lVyc5rOKRO17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Provides utilities for Google Colab environments (likely where this code is running). It is used to access user data\n",
        "from google.colab import userdata\n",
        "\n",
        "# Used to interact with the Groq platform\n",
        "from groq import Groq\n",
        "\n",
        "#Enables integration between the LangChain framework and the Groq platform. LangChain is a framework for developing applications powered by language models.\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "import time\n",
        "\n",
        "#To store the classification results.\n",
        "final_dict = {}\n",
        "\n",
        "# Reads the JSON data from the file and stores it in the test_json variable.\n",
        "with open('/content/testing_data_set.json', 'r') as file:\n",
        "    test_json = json.load(file)\n",
        "\n",
        "# nitialize the Groq Language Model:\n",
        "llm = ChatGroq(\n",
        "    model_name=\"deepseek-r1-distill-llama-70b\",\n",
        "    temperature=0.3,\n",
        "    api_key=userdata.get('GROQ_API_KEY')\n",
        ")\n",
        "\n",
        "# Define the expected JSON structure\n",
        "parser = JsonOutputParser(pydantic_object={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"department\": {\"type\": \"string\"},\n",
        "        \"priority\": {\"type\": \"string\"},\n",
        "        \"language\": {\"type\": \"string\"},\n",
        "        \"type\": {\"type\": \"string\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "# Create a simple prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Classify IT support tickets into JSON with this structure:\n",
        "        {{\n",
        "            \"department\": \"Technical Support, Customer Service, Billing and Payments, Product Support, IT Support, Returns and Exchanges, Sales and Pre-Sales, Human Resources, Service Outages and Maintenance, General Inquiry\",\n",
        "            \"priority\": \"low, medium, high\",\n",
        "            \"language\": \"en, es, fr, de, etc. (full list at https://docs.aws.amazon.com/translate/latest/dg/what-is-languages.html#what-is-languages-supported)\",\n",
        "            \"type\": \"Incident, Request, Problem, Change\"\n",
        "        }}\n",
        "\n",
        "        Examples:\n",
        "        [\n",
        "            {{\n",
        "                \"ticket_ID\": 1001,\n",
        "                \"ticket_subject\": \"Discrepancia de facturación en Google Workspace\",\n",
        "                \"ticket_body\": \"Monto de facturación incorrecto.\",\n",
        "                \"department\": \"Billing and Payments\",\n",
        "                \"type\": \"Incident\",\n",
        "                \"priority\": \"low\",\n",
        "                \"language\": \"es\"\n",
        "            }},\n",
        "            {{\n",
        "                \"ticket_ID\": 1002,\n",
        "                \"ticket_subject\": \"Urgent Consultation Request for Critical IT Issues\",\n",
        "                \"ticket_body\": \"Critical server issues.\",\n",
        "                \"department\": \"Customer Service\",\n",
        "                \"type\": \"Request\",\n",
        "                \"priority\": \"high\",\n",
        "                \"language\": \"en\"\n",
        "            }},\n",
        "            {{\n",
        "                \"ticket_ID\": 1003,\n",
        "                \"ticket_subject\": \"Consulta sobre Servicios de Consultoría en TI\",\n",
        "                \"ticket_body\": \"Info on IT consulting.\",\n",
        "                \"department\": \"General Inquiry\",\n",
        "                \"type\": \"Request\",\n",
        "                \"priority\": \"medium\",\n",
        "                \"language\": \"es\"\n",
        "            }},\n",
        "            {{\n",
        "                \"ticket_ID\": 1004,\n",
        "                \"ticket_subject\": \"Demande de mise à jour des dossiers\",\n",
        "                \"ticket_body\": \"Update employee records.\",\n",
        "                \"department\": \"Human Resources\",\n",
        "                \"type\": \"Change\",\n",
        "                \"priority\": \"low\",\n",
        "                \"language\": \"fr\"\n",
        "            }},\n",
        "            {{\n",
        "                \"ticket_ID\": 1005,\n",
        "                \"ticket_subject\": \"Issues with Slack connection affecting team communication today\",\n",
        "                \"ticket_body\": \"Problems with Slack.\",\n",
        "                \"department\": \"Product Support\",\n",
        "                \"type\": \"Problem\",\n",
        "                \"priority\": \"medium\",\n",
        "                \"language\": \"en\"\n",
        "            }}\n",
        "        ]\n",
        "    \"\"\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Create the chain that guarantees JSON output\n",
        "# Assembles a LangChain chain to process the tickets.\n",
        "# It links the prompt, llm (language model), and parser together. This means:\n",
        "# The prompt is formatted with the ticket data.\n",
        "# The formatted prompt is sent to the llm for classification.\n",
        "# The llm's response is parsed by the parser to ensure JSON output.\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "\n",
        "def classify_ticket(ticket: dict) -> dict:\n",
        "    \"\"\"This function takes a ticket dictionary as input.\n",
        "    It invokes the LangChain chain to classify the ticket.\n",
        "    It prints the classification result (in JSON format).\n",
        "    It stores the result in the final_dict, using the ticket ID as the key.\"\"\"\n",
        "\n",
        "    result = chain.invoke({\"input\": json.dumps(ticket)})\n",
        "    print(json.dumps(result, indent=2))\n",
        "    # Result from LLm is store in final_dict with key as ticket_id\n",
        "    final_dict[ticket['ticket_ID']] = [result.get(\"department\"), result.get(\"type\"), result.get(\"priority\"), result.get(\"language\")]\n",
        "\n",
        "for i in range(0, 500):\n",
        "    print(test_json[i])\n",
        "    classify_ticket(test_json[i])\n",
        "    #Pauses for 15 seconds before processing the next ticket. This is often done to avoid overloading APIs or rate limits.\n",
        "    time.sleep(15)"
      ],
      "metadata": {
        "id": "pJjiWVHpUsIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To write the classified intial data from final_dict variable to submission.csv\n",
        "import csv\n",
        "\n",
        "# Define the header\n",
        "header = ['ticket_ID', 'department', 'type', 'priority', 'language']\n",
        "\n",
        "# Write data to CSV file\n",
        "with open('submission.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    for ticket_id, values in final_dict.items():\n",
        "        writer.writerow([ticket_id] + values)\n",
        "\n",
        "print(\"Data has been written to submission.csv\")"
      ],
      "metadata": {
        "id": "dMYqlgUwYGiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google gen AI LLm is used to predict type and priority\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# The Google Generative AI library used for interacting with their language models.\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "#A library for data validation and parsing using Python type hints\n",
        "from pydantic import BaseModel\n",
        "\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Getting the API Key:\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "\n",
        "# Defines instructions that will be given to the Google GenAI model, guiding it on how to classify tickets.\n",
        "system_instructions = \"\"\"\n",
        "You are an AI model designed to classify IT support tickets.\n",
        "Classify each ticket based on the following attributes:\n",
        "- Priority: low, medium, high\n",
        "- Type: Incident, Request, Problem, Change\n",
        "\"\"\"\n",
        "\n",
        "# Define the expected JSON structure for the ticket classification\n",
        "# Defines the expected format for the AI's classification output. This ensures the output is organized and easily usable.\n",
        "class TicketClassification(BaseModel):\n",
        "    ticket_ID: str\n",
        "    ticket_body: str\n",
        "    ticket_subject: str\n",
        "    priority: str\n",
        "    ticket_type: str\n",
        "\n",
        "# Initialize the GenAI client\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Load the testing data set\n",
        "with open('testing_data_set.json', 'r') as file:\n",
        "    test_json = json.load(file)\n",
        "\n",
        "\n",
        "final_genai_dict = {}\n",
        "\n",
        "# Function to classify a ticket\n",
        "def classify_ticket(ticket: dict) -> dict:\n",
        "    prompt = f\"{system_instructions}\\n\\nTicket:\\nSubject: {ticket['ticket_subject']}\\nBody: {ticket['ticket_body']}\"\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model='gemini-2.0-flash',\n",
        "        contents=prompt,\n",
        "        config={\n",
        "            'response_mime_type': 'application/json',\n",
        "            'response_schema': TicketClassification,\n",
        "        },\n",
        "    )\n",
        "    result = response.parsed\n",
        "    final_genai_dict[ticket['ticket_ID']] = [result.ticket_type, result.priority]\n",
        "\n",
        "# Classify each ticket from testing_data_set.json\n",
        "for i in range(0,500):\n",
        "    print(f\"Classifying ticket {i}\")\n",
        "    classify_ticket(test_json[i])\n",
        "    #Pauses for 3 seconds before processing the next ticket as we have only 15 RPM assuming 1 secound time for classification.\n",
        "    time.sleep(3)"
      ],
      "metadata": {
        "id": "QV6iXY_ceE4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/submission.csv')\n",
        "\n",
        "# Override the 'type' and 'priority' columns in the DataFrame with values from final_genai_dict\n",
        "df['type'] = df['ticketid'].map(lambda x: final_genai_dict[x][0])\n",
        "df['priority'] = df['ticketid'].map(lambda x: final_genai_dict[x][1])\n",
        "\n",
        "# Save the updated DataFrame back to the same CSV file\n",
        "df.to_csv('submission_updated.csv', index=False)\n",
        "\n",
        "print(\"The 'type' and 'priority' columns have been successfully updated and saved to submission_updated.csv.\")"
      ],
      "metadata": {
        "id": "a5fe7TQsgRh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# More accurate information is given to deepseek with more input tokens\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "import json\n",
        "\n",
        "final_depertment_dict = {}\n",
        "\n",
        "\n",
        "with open('testing_data_set.json', 'r') as file:\n",
        "    test_json = json.load(file)\n",
        "\n",
        "# Initialize Groq LLM\n",
        "llm = ChatGroq(\n",
        "    model_name=\"deepseek-r1-distill-llama-70b\",\n",
        "    temperature=0.3,\n",
        "    api_key=userdata.get('GROQ_API_KEY')\n",
        ")\n",
        "\n",
        "# Define the expected JSON structure\n",
        "parser = JsonOutputParser(pydantic_object={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"department\": {\"type\": \"string\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "# Create a simple prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Classify IT support tickets into JSON with this structure:\n",
        "        {{\n",
        "            \"department\": \"Technical Support, Customer Service, Billing and Payments, Product Support, IT Support, Returns and Exchanges, Sales and Pre-Sales, Human Resources, Service Outages and Maintenance, General Inquiry\",\n",
        "\n",
        "        }}\n",
        "        Examples:\n",
        "        [\n",
        "    {{\n",
        "        \"ticket_ID\": 1001,\n",
        "        \"ticket_subject\": \"Discrepancia de facturación en Google Workspace\",\n",
        "        \"ticket_body\": \"Monto de facturación incorrecto en mi suscripción de Google Workspace Business Standard. Por favor, revise y ajuste la factura. Gracias.\",\n",
        "        \"department\": \"Billing and Payments\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1002,\n",
        "        \"ticket_subject\": \"Urgent Consultation Request for Critical IT Issues\",\n",
        "        \"ticket_body\": \"Experiencing critical server issues impacting operations. Urgently need your assistance. Contact via email or phone at <tel_num>. Thank you.\",\n",
        "        \"department\": \"Customer Service\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1003,\n",
        "        \"ticket_subject\": \"Consulta sobre Servicios de Consultoría en TI\",\n",
        "        \"ticket_body\": \"Interesado en información sobre sus Servicios de Consultoría en TI, especialmente en desarrollo de software y administración de servidores. Gracias.\",\n",
        "        \"department\": \"General Inquiry\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1004,\n",
        "        \"ticket_subject\": \"Demande de mise à jour des dossiers\",\n",
        "        \"ticket_body\": \"Demande de mise à jour de notre système de gestion des dossiers des employés pour améliorer l'efficacité et l'intégration avec notre infrastructure informatique. Merci.\",\n",
        "        \"department\": \"Human Resources\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1005,\n",
        "        \"ticket_subject\": \"Issues with Slack connection affecting team communication today\",\n",
        "        \"ticket_body\": \"Challenges activating Kaspersky Internet Security 2024. Need assistance. Contact via <tel_num> or <email>. Thank you.\",\n",
        "        \"department\": \"Product Support\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1006,\n",
        "        \"ticket_subject\": \"Defective Dell XPS 13 9310\",\n",
        "        \"ticket_body\": \"Received Dell XPS 13 9310 with defective display. Please arrange an exchange. Order number: <order_num>. Contact via <email> or <tel_num>. Thanks.\",\n",
        "        \"department\": \"Returns and Exchanges\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1007,\n",
        "        \"ticket_subject\": \"Touchscreen and Keyboard Issues with Surface Pro 7\",\n",
        "        \"ticket_body\": \"Issues with touchscreen response and detachable keyboard on Surface Pro 7. Requesting assistance or replacement. Thank you.\",\n",
        "        \"department\": \"Sales and Pre-Sales\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1008,\n",
        "        \"ticket_subject\": \"AWS-Serverausfall\",\n",
        "        \"ticket_body\": \"Unerwarteter Ausfall unserer AWS-Server. Dringend Unterstützung erforderlich. Danke.\",\n",
        "        \"department\": \"Service Outages and Maintenance\"\n",
        "    }},\n",
        "    {{\n",
        "        \"ticket_ID\": 1009,\n",
        "        \"ticket_subject\": \"Solicitud urgente de orientación y solución de problemas\",\n",
        "        \"ticket_body\": \"Problemas críticos con integración de software y conectividad del servidor. Necesitamos asistencia urgente. Gracias.\",\n",
        "        \"department\": \"Technical Support\"\n",
        "    }}\n",
        "]\n",
        "\n",
        "    \"\"\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Create the chain that guarantees JSON output\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "def classify_ticket(ticket: dict) -> dict:\n",
        "    result = chain.invoke({\"input\": json.dumps(ticket)})\n",
        "    print(json.dumps(result, indent=2))\n",
        "    final_depertment_dict[ticket['ticket_ID']] = result.get(\"department\")\n",
        "\n",
        "for i in range(0, 500):\n",
        "    print(test_json[i])\n",
        "    classify_ticket(test_json[i])\n",
        "    time.sleep(15)"
      ],
      "metadata": {
        "id": "g-9vRry9n0Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('submission_updated.csv')\n",
        "\n",
        "# Override the 'department' column in the DataFrame with values from final_depertment_dict\n",
        "df['department'] = df['ticketid'].map(final_depertment_dict)\n",
        "\n",
        "# Save the updated DataFrame back to the CSV file\n",
        "df.to_csv('final_submission.csv', index=False)\n",
        "\n",
        "print(\"The 'department' column has been successfully updated and saved to final_submission.csv.\")\n"
      ],
      "metadata": {
        "id": "6KUTopw1xvMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}