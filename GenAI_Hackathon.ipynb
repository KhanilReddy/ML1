{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8ug0C-6fA4S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMHiPrl7fLOB",
    "outputId": "c56eb20b-d273-4240-f09c-52196896663a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Qualcomm-DL-Hackathon'...\n",
      "remote: Enumerating objects: 10, done.\u001b[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
      "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (10/10), 30.68 MiB | 25.83 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BI3TJ1GHfaoY"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def extract_all_files(zip_dir, output_dir):\n",
    "    \"\"\"\n",
    "        This function is used to extract all the images from images part-1.zip and images part-2.zip to all_images folder\n",
    "    \"\"\"\n",
    "    if os.path.exists(zip_dir):\n",
    "      # Get the zip files in train directory\n",
    "      files = os.listdir(zip_dir)\n",
    "      zip_files = [f for f in files if f.endswith('.zip')]\n",
    "\n",
    "      if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "      # Extract each zip file\n",
    "      for zip_file in zip_files:\n",
    "          with zipfile.ZipFile(os.path.join(zip_dir, zip_file), 'r') as zip_ref:\n",
    "              for member in zip_ref.namelist():\n",
    "                  # Extract each file to the all_images directory without creating subfolders\n",
    "                  filename = os.path.basename(member)\n",
    "                  if filename:\n",
    "                      source = zip_ref.open(member)\n",
    "                      target = open(os.path.join(output_dir, filename), \"wb\")\n",
    "                      with source, target:\n",
    "                          shutil.copyfileobj(source, target)\n",
    "    else:\n",
    "      print(\"f{zip_dir} doesn't exits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRV5Uk4jfiuX",
    "outputId": "a5bc08f4-77ed-4850-dd82-27846b6009d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been extracted to /content/Qualcomm-DL-Hackathon/train/all_images.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the zip files and the all_images directory\n",
    "train_directory = '/content/Qualcomm-DL-Hackathon/train/'\n",
    "all_images_directory = os.path.join(train_directory , 'all_images')\n",
    "\n",
    "# Extract all files from the zip files to the all_images directory\n",
    "extract_all_files(train_directory, all_images_directory)\n",
    "\n",
    "print(f\"All files have been extracted to {all_images_directory}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DT2FbB2Qfzbm"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Reshape, Activation\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQ3Ge5h7FBYA",
    "outputId": "73452536-f20d-479a-b81d-5ba8975da85f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1646/1646 [00:03<00:00, 442.06it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/content/Qualcomm-DL-Hackathon/train/train.csv')\n",
    "\n",
    "train_img=[]\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "  temp_img = image.load_img('/content/Qualcomm-DL-Hackathon/train/all_images/'+train['image_names'][i], target_size=(128,128))\n",
    "  temp_img=image.img_to_array(temp_img)\n",
    "\n",
    "  train_img.append(temp_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "N1UUhXNYFR5-"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "def vgg16_model(img_rows, img_cols, channel=1, num_classes=None):\n",
    "\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, channel))\n",
    "    # Freeze the layers which you don't want to train\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top of the base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the new model\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XaHiu9zKFWXQ"
   },
   "outputs": [],
   "source": [
    "train_y = train['emergency_or_not'].values\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_y = le.fit_transform(train_y)\n",
    "\n",
    "train_y=to_categorical(train_y)\n",
    "train_y=np.array(train_y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Example to fine-tune on 3000 samples from Cifar10\n",
    "\n",
    "img_rows, img_cols = 128, 128 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "nb_epoch = 15\n",
    "\n",
    "X_train = np.stack(X_train)\n",
    "X_valid = np.stack(X_valid)\n",
    "Y_train = np.stack(Y_train)\n",
    "Y_valid = np.stack(Y_valid)\n",
    "\n",
    "# Load our model\n",
    "model = vgg16_model(img_rows, img_cols, channel, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKZXw6B8Fb9d",
    "outputId": "05d16b3d-0778-45d9-8efb-89bd69c465bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 124ms/step - accuracy: 0.7398 - loss: 24.6171 - val_accuracy: 0.8939 - val_loss: 1.5064\n",
      "Epoch 2/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 89ms/step - accuracy: 0.9421 - loss: 0.5981 - val_accuracy: 0.8879 - val_loss: 0.6155\n",
      "Epoch 3/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9431 - loss: 0.4983 - val_accuracy: 0.9152 - val_loss: 0.3292\n",
      "Epoch 4/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9807 - loss: 0.0801 - val_accuracy: 0.9061 - val_loss: 0.4040\n",
      "Epoch 5/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.9693 - loss: 0.1430 - val_accuracy: 0.9152 - val_loss: 0.3643\n",
      "Epoch 6/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9667 - loss: 0.1257 - val_accuracy: 0.9061 - val_loss: 0.3831\n",
      "Epoch 7/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.9772 - loss: 0.0616 - val_accuracy: 0.9091 - val_loss: 0.5931\n",
      "Epoch 8/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.9699 - loss: 0.0821 - val_accuracy: 0.8939 - val_loss: 0.5784\n",
      "Epoch 9/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.9832 - loss: 0.0528 - val_accuracy: 0.9152 - val_loss: 0.4366\n",
      "Epoch 10/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9772 - loss: 0.0524 - val_accuracy: 0.9182 - val_loss: 0.4453\n",
      "Epoch 11/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9845 - loss: 0.0444 - val_accuracy: 0.9212 - val_loss: 0.3546\n",
      "Epoch 12/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9811 - loss: 0.0603 - val_accuracy: 0.9242 - val_loss: 0.3072\n",
      "Epoch 13/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - accuracy: 0.9865 - loss: 0.0371 - val_accuracy: 0.9242 - val_loss: 0.3877\n",
      "Epoch 14/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.9784 - loss: 0.0745 - val_accuracy: 0.9303 - val_loss: 0.3275\n",
      "Epoch 15/15\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.9680 - loss: 0.0637 - val_accuracy: 0.9242 - val_loss: 0.3374\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,shuffle=True,verbose=1,validation_data=(X_valid, Y_valid))\n",
    "\n",
    "# Make predictions\n",
    "predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "\n",
    "c = np.argmax(predictions_valid, axis=1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2QjAXlEFgJM",
    "outputId": "a13d04b0-1f22-4ec5-d94c-e85782de786a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 706/706 [00:00<00:00, 1054.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/content/Qualcomm-DL-Hackathon/test.csv')\n",
    "\n",
    "test_image = []\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    img = image.load_img('/content/Qualcomm-DL-Hackathon/train/all_images/'+test['image_names'][i], target_size=(128,128))\n",
    "    img = image.img_to_array(img)\n",
    "    test_image.append(img)\n",
    "\n",
    "test_image = np.stack(test_image)\n",
    "test_image.shape\n",
    "\n",
    "# Make predictions\n",
    "predictions_valid2 = model.predict(test_image, batch_size=batch_size, verbose=1)\n",
    "\n",
    "predictions_valid2\n",
    "\n",
    "d = np.argmax(predictions_valid2, axis=1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1nT4NXlUFtOd"
   },
   "outputs": [],
   "source": [
    "# creating submission file\n",
    "sample = pd.read_csv('/content/Qualcomm-DL-Hackathon/test.csv')\n",
    "sample['emergency_or_not'] = d\n",
    "sample.to_csv('/content/Qualcomm-DL-Hackathon/submission.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
